#!/usr/bin/env python3
"""
oss_dedupe_etag.py (v3 - å¸¦åˆ é™¤æ—¥å¿—åŠŸèƒ½)
é»˜è®¤ä¿ç•™æœ€æ–°æ–‡ä»¶ï¼Œå¹¶å¯è®°å½•å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨ã€‚

åœ¨powershellå‘½ä»¤è¡Œé¢„è®¾api key
$env:OSS_AK =""
$env:OSS_SK  =""

ç¬¬ä¸€æ­¥å…ˆä¸å¸¦ --delete,æŸ¥è¯¢é‡å¤å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
python oss_image_remove_duplicates.py --endpoint oss-cn-beijing.aliyuncs.com --bucket ember-grove --prefix image/

ç¬¬äºŒæ­¥å¸¦ --deleteæ‰§è¡Œåˆ é™¤ï¼Œå’Œ --log-deletions duplicates_to_delete.txt å¹¶ä¸”å¯¼å‡ºç›¸å…³ç¬”è®°åˆ—è¡¨

python oss_image_remove_duplicates.py --endpoint oss-cn-beijing.aliyuncs.com --bucket ember-grove --prefix image/ --delete --log-deletions duplicates_to_delete.txt
"""
import oss2, argparse, collections, os, sys, time
from datetime import datetime, timezone


# (å‰é¢çš„è¾…åŠ©å‡½æ•° fmt_ts, build_bucket ç­‰ä¿æŒä¸å˜ï¼Œè¿™é‡Œçœç•¥)
def fmt_ts(ts):
    return datetime.fromtimestamp(ts, tz=timezone.utc).strftime("%Y-%m-%d %H:%M:%S")


def build_bucket(ep, ak, sk, bucket_name):
    auth = oss2.Auth(ak, sk)
    return oss2.Bucket(auth, f"https://{ep}", bucket_name)


def gather_objects(bucket, prefix=None):
    print("â–¶ æ­£åœ¨éå†å¯¹è±¡åˆ—è¡¨ ...")
    it = oss2.ObjectIteratorV2(bucket, prefix=prefix)
    objs = []
    for obj in it:
        objs.append(obj)
    print(f"  æ€»è®¡ {len(objs)} ä¸ªå¯¹è±¡")
    return objs


def group_by_md5(objs, skip_multipart=True):
    groups = collections.defaultdict(list)
    for obj in objs:
        etag = obj.etag.strip('"')
        if "-" in etag and skip_multipart:
            continue
        groups[etag].append(obj)
    return {md5: lst for md5, lst in groups.items() if len(lst) > 1}


def decide_keep(list_obj, rule="latest"):
    if rule == "oldest":
        return sorted(list_obj, key=lambda o: o.last_modified)[0]
    elif rule == "latest":
        return sorted(list_obj, key=lambda o: o.last_modified)[-1]
    else:
        return list_obj[0]


def main():
    parser = argparse.ArgumentParser(description="é€šè¿‡ ETag/MD5 å¯¹ OSS æ–‡ä»¶è¿›è¡Œå»é‡")
    parser.add_argument("--endpoint", required=True, help="Bucket endpoint")
    parser.add_argument("--bucket", required=True, help="Bucket name")
    parser.add_argument("--ak", default=os.getenv("OSS_AK"), help="AccessKeyId (ç¯å¢ƒå˜é‡ OSS_AK)")
    parser.add_argument("--sk", default=os.getenv("OSS_SK"), help="AccessKeySecret (ç¯å¢ƒå˜é‡ OSS_SK)")
    parser.add_argument("--prefix", help="ä»…æ‰«ææŒ‡å®šå‰ç¼€ï¼ˆç›®å½•ï¼‰ä¸‹çš„æ–‡ä»¶")
    parser.add_argument("--rule", choices=["oldest", "latest", "first"], default="latest",
                        help="åœ¨é‡å¤æ–‡ä»¶ä¸­ï¼Œä¿ç•™å“ªä¸€ä¸ªçš„è§„åˆ™ (é»˜è®¤: latest)")
    parser.add_argument("--delete", action="store_true", help="ç¡®è®¤ååˆ é™¤é‡å¤æ–‡ä»¶")

    # --- æ–°å¢å‚æ•° ---
    parser.add_argument("--log-deletions", help="å°†å¾…åˆ é™¤çš„æ–‡ä»¶åè®°å½•åˆ°æŒ‡å®šæ–‡ä»¶")
    # ----------------

    args = parser.parse_args()

    if not args.ak or not args.sk:
        print("âŒ AccessKey æœªæä¾›ï¼Œå¯é€šè¿‡ --ak/--sk æˆ–ç¯å¢ƒå˜é‡ OSS_AK/OSS_SK è®¾ç½®")
        sys.exit(1)

    bucket = build_bucket(args.endpoint, args.ak, args.sk, args.bucket)
    objs = gather_objects(bucket, prefix=args.prefix)
    dup_groups = group_by_md5(objs)

    if not dup_groups:
        print("âœ… æœªå‘ç°é‡å¤æ–‡ä»¶")
        return

    # æ”¶é›†å¾…åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨
    files_to_delete = []
    print(f"\nâš  å‘ç° {len(dup_groups)} ç»„é‡å¤æ–‡ä»¶ï¼š")
    for md5, lst in dup_groups.items():
        keep = decide_keep(lst, args.rule)
        print(f"\nMD5={md5} ï¼ˆä¿ç•™ â†’ {keep.key} @ {fmt_ts(keep.last_modified)}ï¼‰")
        for obj in lst:
            if obj.key == keep.key:
                flag = "KEEP"
            else:
                flag = "DEL "
                files_to_delete.append(obj.key)  # æ”¶é›†å¾…åˆ é™¤çš„æ–‡ä»¶å
            print(f" {flag}  {obj.key:<60}  {fmt_ts(obj.last_modified)}")

    if not args.delete:
        print("\nğŸ’¡ é»˜è®¤ä»…é¢„è§ˆã€‚è‹¥ç¡®è®¤æ— è¯¯ï¼Œé‡æ–°è¿è¡Œæ—¶åŠ å…¥ --delete å³å¯æ‰§è¡Œåˆ é™¤ã€‚")
        return

    confirm = input("\nâš  ç¡®è®¤åˆ é™¤ä¸Šé¢æ ‡è®°ä¸º DEL çš„å¯¹è±¡ï¼Ÿ(yes/no) ").strip().lower()
    if confirm != "yes":
        print("æ“ä½œå·²å–æ¶ˆã€‚")
        return

    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶ï¼Œåˆ™åœ¨åˆ é™¤å‰å†™å…¥
    if args.log_deletions:
        try:
            with open(args.log_deletions, 'w', encoding='utf-8') as f:
                for filename in files_to_delete:
                    f.write(filename + '\n')
            print(f"\nğŸ“ å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨å·²ä¿å­˜è‡³: {args.log_deletions}")
        except IOError as e:
            print(f"âŒ æ— æ³•å†™å…¥æ—¥å¿—æ–‡ä»¶ {args.log_deletions}: {e}")

    # çœŸæ­£åˆ é™¤
    print("\nâ–¶ æ­£åœ¨åˆ é™¤ ...")
    deleted_count = 0
    result = bucket.batch_delete_objects(files_to_delete)
    deleted_count = len(result.deleted_keys)

    print(f"âœ… åˆ é™¤å®Œæˆï¼Œå…±ç§»é™¤ {deleted_count} ä¸ªé‡å¤æ–‡ä»¶")


if __name__ == "__main__":
    main()